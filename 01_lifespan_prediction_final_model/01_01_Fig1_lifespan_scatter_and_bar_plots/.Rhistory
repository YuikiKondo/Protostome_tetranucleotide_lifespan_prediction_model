library(glmnet)
library(caret)
# Set seed for reproducibility
set.seed(123)
# Parameters for the synthetic dataset
n_samples <- 200  # Number of samples
n_features <- 50   # Number of features (CpG-related predictors)
# Generate a random feature matrix (predictors)
X <- matrix(rnorm(n_samples * n_features), nrow = n_samples, ncol = n_features)
head(X)
# Generate a coefficient vector (true relationship between features and target)
true_coefs <- rnorm(n_features, mean = 0, sd = 1)
# Simulate target variable (lifespan) with some added noise
y <- X %*% true_coefs + rnorm(n_samples, mean = 0, sd = 0.5)
# Convert to data frame for compatibility with caret
data <- as.data.frame(X)
data$lifespan <- y
# Print the first few rows of the dataset
head(data)
# Split the dataset into training and test sets using caret
trainIndex <- createDataPartition(data$lifespan, p = .7, list = FALSE)
train_data <- data[trainIndex, ]
test_data <- data[-trainIndex, ]
# Prepare the feature matrix (X) and the target vector (y) for training and testing
X_train <- as.matrix(train_data[, -ncol(train_data)])  # Exclude the 'lifespan' column
y_train <- train_data$lifespan
X_test <- as.matrix(test_data[, -ncol(test_data)])     # Exclude the 'lifespan' column
y_test <- test_data$lifespan
# Run a quick elastic net model using glmnet to check everything works
elastic_net_model <- glmnet(X_train, y_train, alpha = 0.5)  # Alpha set to 0.5 for example
# Print summary of the model
print(elastic_net_model)
data$lifespan
# Load necessary libraries
library(glmnet)
library(glmnetUtils)
library(caret)
# Set seed for reproducibility
set.seed(123)
# Generate synthetic data (as an example)
n_samples <- 200
n_features <- 50
X <- matrix(rnorm(n_samples * n_features), nrow = n_samples, ncol = n_features)
true_coefs <- rnorm(n_features)
y <- X %*% true_coefs + rnorm(n_samples, mean = 0, sd = 0.5)
# Convert X to a data frame for caret usage
data <- as.data.frame(X)
data$lifespan <- y
# Split the dataset into training and test sets
trainIndex <- createDataPartition(data$lifespan, p = .7, list = FALSE)
train_data <- data[trainIndex, ]
test_data <- data[-trainIndex, ]
# Prepare feature matrix and target vector
X_train <- as.matrix(train_data[, -ncol(train_data)])
y_train <- train_data$lifespan
X_test <- as.matrix(test_data[, -ncol(test_data)])
y_test <- test_data$lifespan
# Set up 10-fold outer cross-validation
outer_cv_control <- trainControl(method = "cv", number = 10)
# Define the range of alpha values (discrete)
alpha_values <- seq(0, 1, by = 0.1)
# Define the lambda sequence with 100 values
lambda_values <- seq(0.001, 0.1, length = 100)
# Function to perform nested cross-validation
perform_nested_cv <- function(X_train, y_train, X_test, y_test) {
# Inner cross-validation for hyperparameter tuning
inner_cv_control <- trainControl(method = "cv", number = 10)
# Train model using caret's train() function with 10-fold inner cross-validation
elastic_net_model <- train(
X_train, y_train,
method = "glmnet",
tuneGrid = expand.grid(alpha = alpha_values, lambda = lambda_values),
trControl = inner_cv_control,
metric = "RMSE",
preProcess = c("center", "scale")
)
# Get the minimum alpha and lambda.1se from the inner cross-validation
best_alpha <- elastic_net_model$bestTune$alpha
best_lambda <- elastic_net_model$bestTune$lambda
# Fit the final model using the best alpha and lambda.1se
final_model <- glmnet(X_train, y_train, alpha = best_alpha, lambda = lambda_values)
# Predict on both training and test datasets
train_predictions <- predict(final_model, newx = X_train, s = best_lambda)
test_predictions <- predict(final_model, newx = X_test, s = best_lambda)
# Calculate Pearson's correlation coefficient for both training and test sets
train_corr <- cor(y_train, train_predictions)
test_corr <- cor(y_test, test_predictions)
return(list(train_corr = train_corr, test_corr = test_corr, best_alpha = best_alpha, best_lambda = best_lambda))
}
# Perform nested cross-validation
results <- perform_nested_cv(X_train, y_train, X_test, y_test)
# Load necessary libraries
library(glmnet)
library(glmnetUtils)
library(caret)
# Set seed for reproducibility
set.seed(123)
# Generate synthetic data (as an example)
n_samples <- 200
n_features <- 50
X <- matrix(rnorm(n_samples * n_features), nrow = n_samples, ncol = n_features)
true_coefs <- rnorm(n_features)
y <- X %*% true_coefs + rnorm(n_samples, mean = 0, sd = 0.5)
# Convert X to a data frame for caret usage
data <- as.data.frame(X)
data$lifespan <- y
# Split the dataset into training and test sets
trainIndex <- createDataPartition(data$lifespan, p = .7, list = FALSE)
train_data <- data[trainIndex, ]
test_data <- data[-trainIndex, ]
# Prepare feature matrix and target vector
X_train <- as.matrix(train_data[, -ncol(train_data)])
y_train <- train_data$lifespan
X_test <- as.matrix(test_data[, -ncol(test_data)])
y_test <- test_data$lifespan
# Set up 10-fold outer cross-validation
outer_cv_control <- trainControl(method = "cv", number = 10)
# Define the range of alpha values (discrete)
alpha_values <- seq(0, 1, by = 0.1)
# Define the lambda sequence with 100 values
lambda_values <- seq(0.001, 0.1, length = 100)
# Function to perform nested cross-validation
perform_nested_cv <- function(X_train, y_train, X_test, y_test) {
# Inner cross-validation for hyperparameter tuning
inner_cv_control <- trainControl(method = "cv", number = 10)
# Train model using caret's train() function with 10-fold inner cross-validation
elastic_net_model <- train(
X_train, y_train,
method = "glmnet",
tuneGrid = expand.grid(alpha = alpha_values, lambda = lambda_values),
trControl = inner_cv_control,
metric = "RMSE",
preProcess = c("center", "scale")
)
# Get the minimum alpha and lambda.1se from the inner cross-validation
best_alpha <- elastic_net_model$bestTune$alpha
best_lambda <- elastic_net_model$bestTune$lambda
# Fit the final model using the best alpha and lambda.1se
final_model <- glmnet(X_train, y_train, alpha = best_alpha, lambda = lambda_values)
# Predict on both training and test datasets
train_predictions <- predict(final_model, newx = X_train, s = best_lambda)
test_predictions <- predict(final_model, newx = X_test, s = best_lambda)
# Calculate Pearson's correlation coefficient for both training and test sets
train_corr <- cor(y_train, train_predictions)
test_corr <- cor(y_test, test_predictions)
return(list(train_corr = train_corr, test_corr = test_corr, best_alpha = best_alpha, best_lambda = best_lambda))
}
# Perform nested cross-validation
results <- perform_nested_cv(X_train, y_train, X_test, y_test)
# Load necessary libraries
library(glmnet)
library(glmnetUtils)
library(caret)
# Set seed for reproducibility
set.seed(123)
# Generate synthetic data (as an example)
n_samples <- 200
n_features <- 50
X <- matrix(rnorm(n_samples * n_features), nrow = n_samples, ncol = n_features)
true_coefs <- rnorm(n_features)
y <- X %*% true_coefs + rnorm(n_samples, mean = 0, sd = 0.5)
# Convert X to a data frame for caret usage
data <- as.data.frame(X)
data$lifespan <- y
# Split the dataset into training and test sets
trainIndex <- createDataPartition(data$lifespan, p = .7, list = FALSE)
train_data <- data[trainIndex, ]
test_data <- data[-trainIndex, ]
# Prepare feature matrix and target vector
X_train <- as.matrix(train_data[, -ncol(train_data)])
y_train <- train_data$lifespan
X_test <- as.matrix(test_data[, -ncol(test_data)])
y_test <- test_data$lifespan
# Ensure that the target variable is numeric
y_train <- as.numeric(y_train)
y_test <- as.numeric(y_test)
# Set up 10-fold outer cross-validation
outer_cv_control <- trainControl(method = "cv", number = 10)
# Define the range of alpha values (discrete)
alpha_values <- seq(0, 1, by = 0.1)
# Define the lambda sequence with 100 values
lambda_values <- seq(0.001, 0.1, length = 100)
# Function to perform nested cross-validation
perform_nested_cv <- function(X_train, y_train, X_test, y_test) {
# Inner cross-validation for hyperparameter tuning
inner_cv_control <- trainControl(method = "cv", number = 10)
# Train model using caret's train() function with 10-fold inner cross-validation
elastic_net_model <- train(
X_train, y_train,
method = "glmnet",
tuneGrid = expand.grid(alpha = alpha_values, lambda = lambda_values),
trControl = inner_cv_control,
metric = "RMSE",  # RMSE is the appropriate metric for regression
preProcess = c("center", "scale")
)
# Get the minimum alpha and lambda.1se from the inner cross-validation
best_alpha <- elastic_net_model$bestTune$alpha
best_lambda <- elastic_net_model$bestTune$lambda
# Fit the final model using the best alpha and lambda.1se
final_model <- glmnet(X_train, y_train, alpha = best_alpha, lambda = lambda_values)
# Predict on both training and test datasets
train_predictions <- predict(final_model, newx = X_train, s = best_lambda)
test_predictions <- predict(final_model, newx = X_test, s = best_lambda)
# Calculate Pearson's correlation coefficient for both training and test sets
train_corr <- cor(y_train, train_predictions)
test_corr <- cor(y_test, test_predictions)
return(list(train_corr = train_corr, test_corr = test_corr, best_alpha = best_alpha, best_lambda = best_lambda))
}
# Perform nested cross-validation
results <- perform_nested_cv(X_train, y_train, X_test, y_test)
# Output the results
print(paste("Best Alpha: ", results$best_alpha))
print(paste("Best Lambda: ", results$best_lambda))
print(paste("Training Correlation: ", results$train_corr))
print(paste("Test Correlation: ", results$test_corr))
# Load necessary libraries
library(glmnet)
library(glmnetUtils)
library(caret)
# Set seed for reproducibility
set.seed(123)
# Generate synthetic data (as an example)
n_samples <- 200
n_features <- 50
X <- matrix(rnorm(n_samples * n_features), nrow = n_samples, ncol = n_features)
true_coefs <- rnorm(n_features)
y <- X %*% true_coefs + rnorm(n_samples, mean = 0, sd = 0.5)
# Convert X to a data frame for caret usage
data <- as.data.frame(X)
data$lifespan <- y
# Split the dataset into training and test sets
trainIndex <- createDataPartition(data$lifespan, p = .7, list = FALSE)
train_data <- data[trainIndex, ]
test_data <- data[-trainIndex, ]
# Prepare feature matrix and target vector
X_train <- as.matrix(train_data[, -ncol(train_data)])
y_train <- train_data$lifespan
X_test <- as.matrix(test_data[, -ncol(test_data)])
y_test <- test_data$lifespan
# Ensure that the target variable is numeric
y_train <- as.numeric(y_train)
y_test <- as.numeric(y_test)
# Set up 10-fold outer cross-validation
outer_cv_control <- trainControl(method = "cv", number = 10)
# Define the range of alpha values (discrete)
alpha_values <- seq(0, 1, by = 0.1)
# Define the lambda sequence with 100 values
lambda_values <- seq(0.001, 0.1, length = 100)
# Function to perform nested cross-validation
perform_nested_cv <- function(X_train, y_train, X_test, y_test) {
# Inner cross-validation for hyperparameter tuning
inner_cv_control <- trainControl(method = "cv", number = 10)
# Train model using caret's train() function with 10-fold inner cross-validation
elastic_net_model <- train(
X_train, y_train,
method = "glmnet",
tuneGrid = expand.grid(alpha = alpha_values, lambda = lambda_values),
trControl = inner_cv_control,
metric = "RMSE",  # RMSE is the appropriate metric for regression
preProcess = c("center", "scale")
)
# Get the minimum alpha and lambda.1se from the inner cross-validation
best_alpha <- elastic_net_model$bestTune$alpha
best_lambda <- elastic_net_model$bestTune$lambda
print(elastic_net_model$best)
# Fit the final model using the best alpha and lambda.1se
final_model <- glmnet(X_train, y_train, alpha = best_alpha, lambda = lambda_values)
# Predict on both training and test datasets
train_predictions <- predict(final_model, newx = X_train, s = best_lambda)
test_predictions <- predict(final_model, newx = X_test, s = best_lambda)
# Calculate Pearson's correlation coefficient for both training and test sets
train_corr <- cor(y_train, train_predictions)
test_corr <- cor(y_test, test_predictions)
return(list(train_corr = train_corr, test_corr = test_corr, best_alpha = best_alpha, best_lambda = best_lambda))
}
# Perform nested cross-validation
results <- perform_nested_cv(X_train, y_train, X_test, y_test)
# Output the results
print(paste("Best Alpha: ", results$best_alpha))
print(paste("Best Lambda: ", results$best_lambda))
print(paste("Training Correlation: ", results$train_corr))
print(paste("Test Correlation: ", results$test_corr))
elastic_net_model
library(stringr)
sequence <- "AATGTT"
trinucleotides <- c("AAT", "ATG", "TGT", "GTT")
sapply(trinucleotides, function(tri) str_count(sequence, tri))
library(stringr)
sequence <- "AATGTT"
trinucleotides <- c("AAT", "ATG", "TGT", "GTT", "GAT")
sapply(trinucleotides, function(tri) str_count(sequence, tri))
plot(cars)
plot(cars)
plot(cars)
setwd("/Users/yuikikondo/Desktop/Github_code/protostome_lifespan_prediction_model/03_BUSCO_Miniprot_gene_average_tetranucleotide_1000folds_seed1_alpha1/Fig1_lifespan_scatter_and_bar_plots")
# ===================== Setup =====================
suppressPackageStartupMessages({
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(stringr)
})
input_path <- "log_lifespan_predictions.csv"
output_dir <- dirname(input_path)
# Colors for Train/Test
COLORS <- c("Train" = "#00BFC4", "Test" = "#F8766D")
# Helper: safe saver
save_plot <- function(p, fname, w = 7, h = 5, dpi = 300) {
out <- file.path(output_dir, fname)
ggsave(filename = out, plot = p, width = w, height = h, dpi = dpi)
message("Wrote: ", out)
}
# ===================== Load =====================
df <- read_csv(input_path, show_col_types = FALSE)
req_cols <- c("Dataset", "Known_Log_Lifespan", "Predicted_Log_Lifespan_Model_Averaging")
missing <- setdiff(req_cols, names(df))
if (length(missing) > 0) stop("Missing required column(s): ", paste(missing, collapse = ", "))
# Keep a species/name column if present (optional)
species_col <- intersect(c("Organism.Name","Organism_Name","Species","Final_Tip_Name"), names(df))
species_col <- if (length(species_col) > 0) species_col[1] else NULL
# ===================== Compute errors =====================
# Only Train & Test
df_tt <- df %>%
filter(Dataset %in% c("Train", "Test")) %>%
mutate(
# Back-transform from ln(days) -> years
Known_days  = exp(Known_Log_Lifespan),
Pred_days   = exp(Predicted_Log_Lifespan_Model_Averaging),
Known_years = Known_days / 365,
Pred_years  = Pred_days  / 365,
# Absolute Error in years
Abs_Error_years = abs(Pred_years - Known_years),
# Relative Error on ln-days scale (%)
Log_Diff = Predicted_Log_Lifespan_Model_Averaging - Known_Log_Lifespan,
Rel_Error_pct_log_units = ifelse(
abs(Known_Log_Lifespan) < 1e-12,
NA_real_,
abs(Log_Diff) / abs(Known_Log_Lifespan) * 100
),
# *** Force plotting order: Train left, Test right
Dataset = factor(Dataset, levels = c("Train", "Test"))
)
# Columns to write
out_cols <- unique(c(
"Dataset", species_col,
"Known_years","Pred_years",
"Abs_Error_years",
"Rel_Error_pct_log_units",
"Known_Log_Lifespan","Predicted_Log_Lifespan_Model_Averaging"
))
errors_out <- df_tt %>%
select(all_of(out_cols)) %>%
arrange(Dataset, desc(Abs_Error_years))
out_csv <- file.path(output_dir, "errors_train_test_by_species.csv")
write_csv(errors_out, out_csv)
message("Wrote: ", out_csv)
# ===================== Summaries =====================
summary_tbl <- df_tt %>%
group_by(Dataset) %>%
summarise(
n = dplyr::n(),
Mean_Abs_Error_years   = mean(Abs_Error_years, na.rm = TRUE),
Median_Abs_Error_years = median(Abs_Error_years, na.rm = TRUE),
Mean_Rel_Error_pct_log_units   = mean(Rel_Error_pct_log_units, na.rm = TRUE),
Median_Rel_Error_pct_log_units = median(Rel_Error_pct_log_units, na.rm = TRUE),
.groups = "drop"
)
summary_csv <- file.path(output_dir, "errors_train_test_summary.csv")
write_csv(summary_tbl, summary_csv)
message("Wrote: ", summary_csv)
# ===================== Plots =====================
# ===================== Metrics by Dataset =====================
# Calculate MSE and R² on ln(years) scale
df_tt <- df_tt %>%
mutate(
Known_ln_years = Known_Log_Lifespan - log(365),
Pred_ln_years  = Predicted_Log_Lifespan_Model_Averaging - log(365)
)
metrics_tbl <- df_tt %>%
group_by(Dataset) %>%
summarise(
MSE = mean((Pred_ln_years - Known_ln_years)^2, na.rm = TRUE),
R2  = 1 - sum((Pred_ln_years - Known_ln_years)^2, na.rm = TRUE) /
sum((Known_ln_years - mean(Known_ln_years, na.rm = TRUE))^2, na.rm = TRUE),
.groups = "drop"
)
print(metrics_tbl)
# 1) Known vs Predicted (ln years)
p_scatter_all_years <- ggplot(df_tt,
aes(x = Known_Log_Lifespan - log(365),
y = Predicted_Log_Lifespan_Model_Averaging - log(365),
color = Dataset)) +
geom_abline(slope = 1, intercept = 0,
linetype = 2, linewidth = 0.5, color = "grey40") +
geom_point(alpha = 0.8, size = 2, shape = 16) +
scale_color_manual(values = COLORS) +
scale_x_continuous(breaks = seq(-4, 6, 1), limits = c(-4, 6)) +
scale_y_continuous(breaks = seq(-4, 6, 1), limits = c(-4, 6)) +
coord_equal(xlim = c(-4, 6), ylim = c(-4, 6)) +
labs(
x = "ln(Known lifespan years)",
y = "ln(Predicted lifespan years)"
) +
theme_minimal(base_size = 15) +
theme(legend.position = "none")
# Create label text for Train and Test
metrics_labels <- metrics_tbl %>%
mutate(
label = paste0(Dataset, ": MSE=", round(MSE, 2), ", R²=", round(R2, 3))
)
# Add annotation at different positions
p_scatter_all_years <- p_scatter_all_years +
annotate("text", x = -3.8, y = 5.8, hjust = 0, vjust = 1,
label = metrics_labels$label[metrics_labels$Dataset=="Train"],
size = 4, color = COLORS["Train"]) +
annotate("text", x = -3.8, y = 5.1, hjust = 0, vjust = 1,
label = metrics_labels$label[metrics_labels$Dataset=="Test"],
size = 4, color = COLORS["Test"])
print(p_scatter_all_years)
save_plot(p_scatter_all_years, "plot_known_vs_pred_ln_years_train_test.png", w = 6, h = 5)
# ===================== Fixed label placement =====================
# Absolute error stats (means only)
means_abs <- df_tt %>%
group_by(Dataset) %>%
summarise(mean_abs = mean(Abs_Error_years, na.rm = TRUE), .groups = "drop")
# Relative error stats (means only)
means_rel <- df_tt %>%
group_by(Dataset) %>%
summarise(mean_rel = mean(Rel_Error_pct_log_units, na.rm = TRUE), .groups = "drop")
# 2) Absolute Error plot (labels at y = 120)
p_box_abs_log <- ggplot(df_tt, aes(x = Dataset, y = pmax(Abs_Error_years, 1e-6), fill = Dataset)) +
geom_boxplot(outlier.shape = NA, width = 0.4) +
geom_jitter(width = 0.15, alpha = 0.4, size = 1) +
geom_text(
data = means_abs,
aes(x = Dataset,
y = 120,   # fixed position at y = 120
label = paste0("Mean = ", sprintf("%.2f", mean_abs), " y"),
color = Dataset),
inherit.aes = FALSE, size = 5, fontface = "bold"
) +
scale_y_log10(breaks = c(0.01, 0.1, 1, 10, 100),
labels = c("0.01", "0.1", "1", "10", "100"),
limits = c(0.01, 120)) +
scale_fill_manual(values = COLORS) +
scale_color_manual(values = COLORS) +
labs(x = "", y = "Absolute error (years)") +
theme_minimal(base_size = 19) +
theme(legend.position = "none")
save_plot(p_box_abs_log, "box_abs_error_years_log10_train_test.png", w = 5, h = 5)
# 3) Relative Error plot (labels at y = 120)
p_box_rel_log_units <- ggplot(df_tt, aes(x = Dataset, y = Rel_Error_pct_log_units, fill = Dataset)) +
geom_boxplot(outlier.shape = NA, width = 0.4, na.rm = TRUE) +
geom_jitter(width = 0.15, alpha = 0.4, size = 1, na.rm = TRUE) +
geom_text(
data = means_rel,
aes(x = Dataset,
y = 120,   # fixed position at y = 120
label = paste0("Mean = ", sprintf("%.1f", mean_rel), "%"),
color = Dataset),
inherit.aes = FALSE, size = 5, fontface = "bold"
) +
scale_y_continuous(breaks = seq(0, 120, 20), limits = c(0, 120)) +
scale_fill_manual(values = COLORS) +
scale_color_manual(values = COLORS) +
labs(x = "", y = "Relative error (%)") +
theme_minimal(base_size = 19) +
theme(legend.position = "none")
save_plot(p_box_rel_log_units, "box_rel_error_pct_ln_days_train_test.png", w = 5, h = 5)
# ===================== Console outputs =====================
print(summary_tbl)
